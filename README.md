
# PriorBrush: Dual-Stage Diffusion Distillation with Prior-Aware Refinement for Real-Time Text-to-Image Synthesis
> ⚠️ **NOTE:** This research is an automatic research using Research Graph.
## Abstract
In this work, we tackle the dual challenges of achieving high-fidelity image synthesis and real‐time inference in text-to-image generation by building upon the SwiftBrush approach \cite{2312.05239v7} and incorporating ideas from diffusion-based prior estimation originally developed for text-to-3D synthesis. SwiftBrush employs a re-parameterized variational score distillation loss that enables one-step generation; specifically, a pretrained text-to-image diffusion teacher is distilled into a student network that synthesizes a coarse, high-level image directly from a noise vector via a loss defined as \(L_{vsd} = \mathbb{E}_{z\sim\mathcal{N}(0,I)}\Big[\|\tilde{x} - x\|^2\Big]\), where \(\tilde{x}\) denotes the predicted clean image. Although this one-shot synthesis guarantees rapid inference, it suffers from a degradation of fine details and exhibits high sensitivity to hyperparameter tuning compared to its multi-step teacher model. To overcome these limitations without incurring the full computational cost of multi-step sampling, we propose PriorBrush, a novel dual-stage diffusion distillation framework that first generates a coarse image using one-step variational score distillation and subsequently applies a fast, adaptive diffusion-based refinement module to recover missing structural details and mitigate artifacts. In the second stage, a lightweight diffusion-based prior estimator performs a limited reverse diffusion process to estimate a Content Prior (CP) and inject fine texture corrections through an adaptively conditioned loss function. This refinement module leverages learned degradation and content representations obtained from a small paired dataset of high- and low-quality images, and is guided by both the input text prompt and an internal content degradation map that tracks discrepancies between the coarse output and the target high-fidelity image. Our experimental evaluation, implemented in Python using PyTorch, NumPy, and scikit-image, is organized into three main experiments. In Experiment 1, we quantitatively compare the inference latency and output quality of SwiftBrush and PriorBrush by conducting multiple trials with varying random seeds and measuring metrics such as Frechet Inception Distance (FID), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS). The results reveal that while the one-step generation of SwiftBrush is extremely fast, it consistently produces images with minor artifacts and reduced detail; in contrast, PriorBrush achieves significant improvements in fine detail through a few additional diffusion steps in the refinement module without sacrificing real-time performance. In Experiment 2, an ablation study compares a full PriorBrush pipeline that includes both the one-step generation and the diffusion-based refinement with a variant that omits the refinement stage; the analysis shows that the complete PriorBrush framework yields superior detail resolution and lower levels of artifacts, as evidenced by higher SSIM values and lower LPIPS scores. In Experiment 3, a sensitivity analysis is conducted by varying the number of reverse diffusion steps in the refinement module (using 2, 3, and 5 steps) while keeping other parameters fixed; this study elucidates the trade-off between computational overhead and quality gains, demonstrating that quality improvements tend to saturate after a small number of refinement steps, which justifies the lightweight design of our approach. The key contributions of our work are multifold: \begin{itemize} \item[\textbf{Dual-Stage Integration:}] We propose a hybrid architecture that initially employs one-step variational score distillation to generate a coarse image and subsequently applies a fast diffusion-based refinement, thereby balancing inference speed with high image quality. \item[\textbf{Robust Quality Improvement:}] The additional refinement stage effectively recovers fine details and reduces artifacts inherent in one-shot synthesis, achieving performance closer to that of computationally intensive multi-step methods without their full overhead. \item[\textbf{Reduced Hyperparameter Sensitivity:}] By decoupling the coarse image generation from the refinement process, our method exhibits reduced sensitivity to hyperparameter tuning, resulting in a more robust and easily deployable system. \item[\textbf{Practical Efficiency:}] Requiring only a few additional diffusion steps in the refinement phase, PriorBrush maintains real-time applicability while delivering image quality competitive with established multi-step approaches. \end{itemize} In summary, PriorBrush synergistically combines the rapid inference capabilities of one-step variational score distillation with the quality-enhancing benefits of a targeted diffusion-based refinement module, thereby bridging the gap between speed and high-fidelity synthesis in text-to-image generation. Future extensions of this framework may include support for few-step generation and integration with additional conditioning mechanisms to further advance generative performance in diverse scenarios.

- [Full paper](https://github.com/auto-res2/auto-research/blob/devin-48dfa253b7f049aa9cb4bbac0f7b8dbf/paper/paper.pdf)
- [Related work](http://arxiv.org/abs/2312.05239v7)
- [Research Graph execution log](https://github.com/auto-res2/auto-research/blob/devin-48dfa253b7f049aa9cb4bbac0f7b8dbf/logs/research_graph_log.json)
- [Devin execution log](https://app.devin.ai/sessions/48dfa253b7f049aa9cb4bbac0f7b8dbf)