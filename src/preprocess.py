"""
Data preprocessing for CAAD experiments.
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
import numpy as np
import cv2  # OpenCV for Gaussian filtering
import os

def ensure_dirs_exist():
    """Create necessary directories if they don't exist."""
    dirs = ['data', 'logs', 'models', 'config']
    for d in dirs:
        os.makedirs(d, exist_ok=True)

def get_datasets(dataset_name='CIFAR10'):
    """Load and prepare datasets."""
    transform = transforms.Compose([
        transforms.ToTensor(),  # images scaled to [0,1]
    ])
    
    if dataset_name == 'CIFAR10':
        train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
        test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    else:
        raise ValueError(f"Dataset {dataset_name} not supported")
    
    return train_dataset, test_dataset

def get_data_loaders(train_dataset, test_dataset, batch_size=64, num_workers=4):
    """Create data loaders for training and testing."""
    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)
    return train_loader, test_loader

def get_subloader(dataset, percent, batch_size=64, num_workers=4):
    """Returns a DataLoader for a random subset of the dataset."""
    from torch.utils.data import Subset
    num_samples = int(len(dataset) * percent)
    indices = torch.randperm(len(dataset))[:num_samples]
    subset = Subset(dataset, indices)
    return torch.utils.data.DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=num_workers)

def add_structured_noise(image, alpha=0.8, beta=0.2, kernel_size=7, sigma=2.0):
    """
    Adds structured noise to a single image tensor.
    The structured noise is generated by applying a Gaussian Blur (via OpenCV) to random noise.
    
    Args:
        image: torch.Tensor shape (C,H,W)
        alpha: weight for the original image
        beta: weight for the structured noise
        kernel_size: size of the Gaussian kernel for blurring
        sigma: standard deviation for the Gaussian kernel
    
    Returns:
        torch.Tensor: corrupted image
    """
    device = image.device
    
    noise = torch.randn_like(image)
    
    noise_np = noise.permute(1, 2, 0).cpu().numpy()
    noise_filtered = np.zeros_like(noise_np)
    
    for ch in range(noise_np.shape[-1]):
        noise_filtered[:, :, ch] = cv2.GaussianBlur(
            noise_np[:, :, ch], 
            (kernel_size, kernel_size), 
            sigmaX=sigma
        )
    
    noise_filtered = torch.from_numpy(noise_filtered).permute(2, 0, 1).to(device)
    
    corrupted = alpha * image + beta * noise_filtered
    
    return torch.clamp(corrupted, 0., 1.)
